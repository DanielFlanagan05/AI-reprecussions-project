<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="styles.css">
  <title>My Website</title>
</head>
<body>
  <header>
    <nav>
      <ul>
        <li><a href="#home" id="homeBtn">Home</a></li>
        <li><a href="#example1" id="example1Btn">Example1</a></li>
        <li><a href="#example2" id="example2Btn">Example2</a></li>
        <li><a href="#references" id="referencesBtn">References</a></li> <!-- Added References tab button -->
      </ul>
    </nav>
  </header>
  <main>
    <section id="home" class="tab">
      <!-- Add your content for the Home tab here -->
      <h1>Societies Artificial Intelligence Blindspot</h1>
      <p>Artificial Intelligence, or AI, is an interdisciplinary field drawing on concepts from computer science, data science, statistics, 
        cognitive psychology, and neuroscience. It entails the development of computer systems that can perform tasks that typically require human
        intelligence, such as visual perception, speech recognition, decision making, and language translation. AI is created using algorithms and
        mathematical models that allow computers to learn from data and experience, and then make predictions or decisions based on that learning. 
        <br>
        <br>
        One way to think of AI is like a brain for a computer. Just like how our brains process information and make decisions based on our
        experiences and learning, AI algorithms do the same for computers. They can analyze vast amounts of data and recognize patterns, and because
        they are able to analyze much greater quantities than humans in a short amount of time, and do not rely on faulty memory, they can recognize
        patterns that humans might miss.
        <br>
        <br>
        However, unlike humans, AI models view data objectively. They are not capable of emotion or cognitive biases in the way humans are. The 
        algorithms used to create AI are provided a data set, analyze it using algorithms pre-determined by its developers, and make predictions and
        conclusions to future information based on what it has learned from the data sets it was provided. This can come in many forms, the most
        notable one currently would be Large Languange Models (LLM). An LLM is designed to process and generate human-like language using neural
        networks, which are computational models inspired by the structure and function of the human brain. They are capable of recieving an input from 
        a user in the form of text, and generating a response to the query based on the data set it was previously provided. But, the term AI is not
        limited to the form of LLMs. There are AI algorithms that are able to accomplish various other feats using pattern recognition, such as 
        facial, spacial, and image recognition. Each of these have the potential to analyze information and generate conclusions in a much faster -
        and potentially more accurate - ways than a human could, for example facial recognition could be used to quickly review thousands of hours of 
        video to identify a potential perpetrator of a crime, and spacial recognition has applications in autonomous driving by identifying the 
        surroundings of a car such as the roadlines, which can then be expanded with image recognition to identify humans and animals in the car's
        path that the AI must make decisions to avoid colliding with. 
        <br>
        <br>
        Due to AI's lack of emotional capabilities, one may conclude that an AI is intrinsically free of bias. Unfortunately, this is not necessarily
        true. The conclusions drawn by AI algorithms are dependent upon both the algorithm itself, and the data set the algorithm is provided. These
        both are subject to bias, intentional or not, by the developer. In order for an Artificial Intelligence to truly be unbiased, the data set it
        was trained on must also be unbiased. So far though, AI in practice has not shown itself to be unbiased. An example of bias is the skewed 
        capability of AI to recognize the faces of women and people of color. Overall, in 2019, Microsoft's facial detection AI was shown to have
        an accuracy of 93.7%, FACE++ 90%, and IBM 87.9%. This might seem decently accurate. However, when breaking this data down by gender, it has 
        been shown that all of these algorithms work better on male faces compared to female faces, and when further broken down by skin color, 
        Microsoft's AI only has an accuracy of 87.1%, FACE++ 83.5%, and IBM 77.6%. This means there is a 12-19% error gap between darker and lighter
        skin tones (Buolamwini, 2019a). 
      </p>
      <img src="images/face_recognition.png" alt="Face Recognition"> <!-- Added the image -->
      <p> The large misconception regarding Artificial Intelligence is that people should fear the possibility of AI becoming sentient, and deciding
        to destroy humanity. Even if it is possible for AI to acquire sentience though, the only way in which it would truly become a threat is if the
        data it was trained on and the algorithms that created it provide it with the capability of a desire to cause harm to humans, and this is a 
        large IF to begin with, as there is not sufficient evidence that AI could become sentient, and that it would be able to generate its own 
        motives even if it was. This fear of an unlikely scenario that incites fear is due to a primal instinct of self preservation that causes 
        us to identify a scenario that seems possible and dangerous, even if it that scenario is so improbable it is essentially impossible. This
        specific fear is largely the result of media consumption where the concept of AI sentience is presented as both a possibility and a dangerous one,
        and unfortunately has become the most commonly observed fear in regard to AI by our society. The focus of our fear on this unlikely scenario 
        has clouded our ability to recognize the real, present day dangers of AI, and prevents us from focussing our attention on preventing these real
        scenarios of danger by holding those responsible for the creation of AI algorithms accountable (Rosling, 2018).
      </p>

    </section>
    <section id="example1" class="tab" style="display: none;">
      <!-- Add your content for Example1 tab here -->
      <h1>Bias in Artificial Intelligence</h1>
      <p>
        Biases within Artificial Intelligence have already caused tangible damage. Automated tools are already being used to screen people looking to 
        buy a home or rent an apartment. However, they have imperfections that can cause devastating consequences. In Michigan, a man was 
        wrongly accused of fraud and had to file for bankruptcy. He had never committed unemployment insurance fraud, or attempted to do so. 
        However, the AI used to identify people who have commit fraud wrongly identified him, and it resulted in nearly $11,000 being seized from
        his tax refund check (Johnson, 2021). Furthermore, on the home page a study was included that identified a 12-19% gap in error between facial 
        identification accuracy between darker and ligther skinned individuals. In another study, the results were even more substancial, identifying
        only a 1% error rate for lighter-skinned men, and 35% error rate in darker-skinned women. These AI systems failed to identify the faces of 
        even some of the most influencial figures, such as Oprah Winfrey, Michelle Obama, and Serena Williams (Buolamwini, 2019b).
        <br>
        https://www.freep.com/story/news/local/michigan/2019/12/22/government-artificial-intelligence-midas-computer-fraud-fiasco/4407901002/

        <br>
        <br>
        AI has also been used to identify students and rate teachers. Its mistakes disproportionately have harmed people of color. The system has
        improperly rated teachers, graded students, and flagged people with dark skin more often for cheating on tests (Johnson, 2021).
        <br>
        <br>
        Thankfully, there has been some effort to hold users accountable for the consequential mistakes of AI. In New York City, a law has
        been adopted requiring audits of algorithms used for hiring and promotions by employers. It must be audited by an outside organization
        to assess whether an algorithm exhibits bias based on race, sex, or ethnicity. Employers also are required to disclose whether AI is
        used when deciding who gets hired or promoted. Furthermore, in Washington, DC, Congress drafted a bill requiring businesses to evaluate automated decisionmaking systems used in impactful industries
        such as health care, housing, employment, and education (Johnson, 2021).
        <br>
        <br>
        Much of the observed bias may be attributable to the lack of diversity within the groups developing these algirhtms. Less than 2% 
        of the employees in technical roles at Facebook and Google are black, and an estimated 1/5 of the technical workforce are women. While 
        this presents a clear problem with diverse representation of people working these impactful roles, it may also present a relatively
        simple solution to the issue of AI bias: increasing the represenation of different groups within these positions (Buolamwini, 2019b).
        </p>
    </section>
    <section id="example2" class="tab" style="display: none;">
      <!-- Add your content for Example2 tab here -->
      <h1>Example2</h1>
      <p>This is the Example2 tab. You can add any content related to Example2 here.</p>
    </section>
    <section id="references" class="tab" style="display: none;">
      <!-- Add your text content for the References tab here -->
      <h1>References</h1>
      <p>
        Rosling, H., & Rosling, O., & Rosling Rönnlund, A. (2018). 
            Factfulness: Ten reasons we’re wrong about the world — and why things are better than you think. Flatiron Books.
        
        <br>
        <br>

        Johnson, K. (2021, December 2). 
            The movement to hold AI accountable gains more steam. 
            WIRED. https://www.wired.com/story/movement-hold-ai-accountable-gains-steam/

        <br>
        <br>

        Buolamwini, J. [Bloomberg Live]. (2019, March 29). 
            The coded gaze: Bias in Artificial Intelligence | Equality Summit [Video]. 
            YouTube. https://www.youtube.com/watch?v=eRUEVYndh9c
        
        <br>
        <br>
            
        Desbiolles, R. (2021, December 27). 
            BlackRock Aladdin – Intelligence Finance: Why AI is shaping the future of banking. 
            UCL FinTech Society. https://www.uclftr.com/post/blackrock-aladdin-intelligent-finance-why-ai-is-shaping-the-future-of-banking
        
        <br>
        <br>
            
        Buolamwini, J. (2019, February 7). 
            Artificial Intelligence Has a Problem With Gender and Racial Bias. Here’s How to Solve It. 
            TIME USA. https://time.com/5520558/artificial-intelligence-racial-gender-bias/ 

      </p>
    </section>
  </main>
  <script src="script.js"></script>
</body>
</html>
